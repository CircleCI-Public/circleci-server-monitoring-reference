global:
  enabled: true
  # -- List of image pull secrets to be used across the deployment
  imagePullSecrets: []
  # -- Override the release name
  nameOverride: ""
  # -- Override the full name for resources
  fullnameOverride: "server-monitoring"

prometheusOperator:
  enabled: "-"
  installCRDs: false
  crds:
    annotations:
      "helm.sh/resource-policy": "keep"
  # -- Number of Prometheus Operator replicas to deploy.
  replicas: 1
  image:
    # -- Image repository for Prometheus Operator.
    repository: quay.io/prometheus-operator/prometheus-operator
    # -- Tag for the Prometheus Operator image.
    tag: v0.89.0
  prometheusConfigReloader:
    image:
      # -- Image repository for Prometheus Config Reloader.
      repository: quay.io/prometheus-operator/prometheus-config-reloader
      # -- Tag for the Prometheus Config Reloader image.
      tag: v0.81.0

prometheus:
  enabled: "-"
  # -- Number of Prometheus replicas to deploy.
  replicas: 2
  image:
    # -- Image repository for Prometheus.
    repository: quay.io/prometheus/prometheus
    # -- Tag for the Prometheus image.
    tag: v3.2.1
  serviceMonitor:
    # -- Labels to select ServiceMonitors for scraping metrics.
    # By default, it's configured to scrape the existing Telegraf and Tempo deployments in CircleCI server.
    selectorLabels:
      app.kubernetes.io/instance: circleci-server
    # -- Match ServiceMonitors with specific names
    selectorExpressions:
      - key: app.kubernetes.io/name
        operator: In
        values: ["telegraf", "tempo", "opentelemetry-collector"]
    # -- Namespaces to look for ServiceMonitor objects. Set this if the CircleCI
    # server monitoring stack is deploying in a different namespace than the
    # actual CircleCI server installation.
    selectorNamespaces: []
    endpoints:
      - # -- Port name for the Prometheus client service.
        port: prometheus-client
        # Default ServiceMonitor labels that are dropped since
        # they overwrite app metric labels and are not useful
        # as they always point to the server Telegraf instance.
        relabelings:
          - regex: (container|endpoint|namespace|pod|service)
            action: labeldrop
        metricRelabelings:
          - regex: instance
            action: labeldrop
  persistence:
    # -- Enable persistent storage for Prometheus.
    enabled: false
    # -- Access modes for the persistent volume.
    accessModes:
      - ReadWriteOnce
    # -- Size of the persistent volume claim.
    size: 10Gi
    # -- Storage class for persistent volume provisioner. You can create a custom
    # storage class with a "retain" policy to ensure the persistent volume
    # remains even after the chart is uninstalled.
    storageClass: ""

# -- Full values for the Grafana Operator chart can be obtained at:
# https://github.com/grafana/grafana-operator/blob/master/deploy/helm/grafana-operator/values.yaml
grafanaoperator:
  # -- Overrides the fully qualified app name.
  fullnameOverride: "server-monitoring-grafana-operator"
  image:
    # -- Image repository for the Grafana Operator.
    repository: quay.io/grafana-operator/grafana-operator
    # -- Tag for the Grafana Operator image.
    tag: v5.18.0

grafana:
  enabled: "-"
  # -- Number of Grafana replicas to deploy.
  replicas: 1
  image:
    # -- Image repository for Grafana.
    repository: grafana/grafana
    # -- Tag for the Grafana image.
    tag: 12.0.0-security-01
  credentials:
    # -- Name of an existing secret for Grafana credentials. Leave empty to create a new secret.
    existingSecretName: ""
    # -- Grafana admin username.
    adminUser: "admin"
    # -- Grafana admin password. Change from default for production environments.
    adminPassword: "admin"
  service:
    # -- Specifies the type of service for Grafana. Options include ClusterIP,
    # NodePort, or LoadBalancer. Use NodePort or LoadBalancer to expose
    # Grafana externally. Ensure that grafana.credentials are set for
    # security purposes.
    type: "ClusterIP"
    # -- Port on which the Grafana service will be exposed.
    port: 3000
    # -- Metadata annotations for the service.
    annotations: {}
  ingress:
    # -- Enable to create an Ingress resource for Grafana. Disabled by default.
    enabled: false
    # -- Specifies the class of the Ingress controller. Required if the
    # Kubernetes cluster includes multiple Ingress controllers.
    className: ""
    # -- Hostname to use for the Ingress. Must be set if Ingress is enabled.
    host: ""
    tls:
      # -- Enable TLS for Ingress. Requires a TLS secret to be specified.
      enabled: false
      # -- Name of the TLS secret used for securing the Ingress. Must be
      # provided if TLS is enabled.
      secretName: ""
  # -- Add any custom Grafana configurations you require here. This should be a
  # YAML-formatted string of additional settings for Grafana.
  extraConfig: ""
  persistence:
    # -- Enable persistent storage for Grafana.
    enabled: false
    # -- Access modes for the persistent volume.
    accessModes:
      - ReadWriteOnce
    # -- Size of the persistent volume claim.
    size: 10Gi
    # -- Storage class for persistent volume provisioner. You can create a custom
    # storage class with a "retain" policy to ensure the persistent volume
    # remains even after the chart is uninstalled.
    storageClass: ""
  datasource:
    jsonData:
      # -- The time interval for Grafana to poll Prometheus.
      # Specifies the frequency of data requests.
      timeInterval: 5s
  dashboards:
    # -- The directory containing JSON files for Grafana dashboards.
    jsonDirectory: dashboards

tempo:
  # -- Enable Tempo distributed tracing
  # Requires manual installation of Tempo Operator
  # Set to true to enable, false to disable, "-" to use global default
  enabled: "-"
  # -- Resource requirements for Tempo pods
  # Adjust based on your trace volume and cluster capacity
  resources:
    requests:
      # -- Minimum CPU guaranteed to Tempo pods
      cpu: 500m
      # -- Minimum memory guaranteed to Tempo pods
      memory: 1Gi
    limits:
      # -- Maximum CPU Tempo pods can use
      cpu: 1000m
      # -- Maximum memory Tempo pods can use
      memory: 2Gi
  # -- Storage configuration for trace data
  storage:
    traces:
      # -- Storage backend for traces
      # Default: in-memory storage (traces lost on pod restart)
      # Suitable for development/testing environments only
      backend: memory

      # -- Persistent Volume storage
      # Stores traces on persistent disk attached to the pod
      # backend: pv

      # -- Cloud storage backends
      # Choose based on your CircleCI server deployment location:

      # -- AWS S3 (use if CircleCI server is on AWS)
      # backend: s3
      # s3:
      #   credentialMode: "<static|token|token-cco>"
      #   secret: tempo-s3-secret

      # -- Google Cloud Storage (use if CircleCI server is on GCP)
      # backend: gcs
      # gcs:
      #   secret: tempo-gcs-secret

      # -- Storage volume size
      # For memory/pv: actual volume size
      # For cloud backends: size of WAL (Write-Ahead Log) volume
      # Increase for higher trace volumes or longer retention
      size: 20Gi
      # -- Storage class for persistent volume provisioner. Applies to both
      # persistent volume and object storage backends.
      storageClassName: ""
  # -- Pod security context for Tempo containers
  podSecurityContext:
    # -- Run containers as non-root user
    runAsNonRoot: true
    # -- User ID to run the container processes
    runAsUser: 10001
    # -- Group ID to run the container processes
    runAsGroup: 10001
    # -- Filesystem group ID for volume ownership and permissions
    fsGroup: 10001
  # -- Add any custom Tempo configurations you require here. This should be a
  # YAML object of additional settings for Tempo.
  extraConfig: {}
  # -- Exposes Tempo RED metrics for Prometheus
  serviceMonitor:
    # -- Enable ServiceMonitor creation for Tempo metrics
    enabled: true
    # -- Endpoints configuration for metrics scraping
    endpoints:
      - port: http
        path: /metrics
        interval: 30s
